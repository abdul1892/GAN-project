# Sketch-to-Clothing Visuals Using CycleGAN

This project implements a **Cycle-Consistent Generative Adversarial Network (CycleGAN)** to transform hand-drawn **sketches** into realistic **clothing visuals**. The model is trained to learn the mapping between sketches and corresponding clothing images, enabling designers to visualize clothing concepts directly from sketches.

## **Features**

## **Features**
- **Sketch Transformation**: Converts hand-drawn or digital sketches into realistic clothing images.
- **Bidirectional Translation**: Supports sketch-to-visual and visual-to-sketch transformations.
- **Self-Adaptive Training**: Utilizes cyclic consistency loss to maintain transformation integrity in both directions.
- **Customizable Dataset**: Allows users to train the model with their own datasets for more personalized output.

## **Technology Stack**

- **Python** for core development.
- **TensorFlow/Keras** for building and training the CycleGAN model.
- **OpenCV** for image pre-processing and visualization.
- **NumPy** and **Pandas** for data handling.

## **Contact**

- **Name:** Z Mohammed Ghayaz
- **Email:** [mdghayaz04@gmail.com](mailto:mdghayaz04@gmail.com)  
- **LinkedIn:** [Mohammed Ghayaz | LinkedIn](https://linkedin.com/in/mohammed-ghayaz) 