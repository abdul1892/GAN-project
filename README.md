# Sketch-to-Clothing Visuals Using CycleGAN

This project implements a **Cycle-Consistent Generative Adversarial Network (CycleGAN)** to transform hand-drawn **sketches** into realistic **clothing visuals**. The model is trained to learn the mapping between sketches and corresponding clothing images, enabling designers to visualize clothing concepts directly from sketches.

## **Features**

## **Features**
- **Sketch Transformation**: Converts hand-drawn or digital sketches into realistic clothing images.
- **Bidirectional Translation**: Supports sketch-to-visual and visual-to-sketch transformations.
- **Self-Adaptive Training**: Utilizes cyclic consistency loss to maintain transformation integrity in both directions.
- **Customizable Dataset**: Allows users to train the model with their own datasets for more personalized output.

## **Technology Stack**

- **Python** for core development.
- **TensorFlow/Keras** for building and training the CycleGAN model.
- **OpenCV** for image pre-processing and visualization.
- **NumPy** and **Pandas** for data handling.

## **Contact**

- **Name:** Z Mohammed Ghayaz
- **Email:** [abdulrahman965@gmail.com](mailto:abdulrahmanj965@gmail.com)  
- **LinkedIn:** [Abdul Rahman J | LinkedIn](https://www.linkedin.com/in/abdul-rahman-j-a60b3a259/) 
